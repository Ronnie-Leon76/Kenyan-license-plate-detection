{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License plate detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from os.path import splitext,basename\n",
    "from keras.models import model_from_json\n",
    "import glob\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from local_utils import detect_lp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to load character detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    try:\n",
    "        path = splitext(path)[0]\n",
    "        with open('%s.json' % path, 'r') as json_file:\n",
    "            model_json = json_file.read()\n",
    "        model = model_from_json(model_json, custom_objects={})\n",
    "        model.load_weights('%s.h5' % path)\n",
    "        print(\"Model loaded successfully!\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(e)  \n",
    "wpod_net_path = \"./wpod-net.json\"\n",
    "wpod_net = load_model(wpod_net_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Images For Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = glob.glob(\"Kenyan_Vehicles_License_Plates/*.png\")\n",
    "\n",
    "def preprocess_image(image_path,resize=False):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img / 255\n",
    "    if resize:\n",
    "        img = cv2.resize(img, (224,224))\n",
    "    return img\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "cols = 3\n",
    "rows = 3\n",
    "fig_list = []\n",
    "\n",
    "for i, image_path in enumerate(image_paths):\n",
    "    if i >= cols * rows:\n",
    "        break\n",
    "\n",
    "    fig_list.append(fig.add_subplot(rows, cols, i + 1))\n",
    "    title = splitext(basename(image_path))[0]\n",
    "    fig_list[-1].set_title(title)\n",
    "    img = preprocess_image(image_path)\n",
    "    plt.axis(False)\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License plate detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plate(image_path, Dmax=500, Dmin=400):\n",
    "    vehicle = preprocess_image(image_path)\n",
    "    ratio = float(max(vehicle.shape[:2])) / min(vehicle.shape[:2])\n",
    "    side = int(ratio * Dmin)\n",
    "    bound_dim = min(side, Dmax)\n",
    "    _ , LpImg, _, cor = detect_lp(wpod_net, vehicle, bound_dim, lp_threshold=0.5)\n",
    "    return LpImg, cor\n",
    "\n",
    "# Retrieve license plate image and its coordinates\n",
    "test_image = image_paths[20]\n",
    "LpImg,cor = get_plate(test_image)\n",
    "print(\"Detect %i plate in\"%len(LpImg),splitext(basename(test_image))[0])\n",
    "print(\"Coordinate of plate in image: \\n\", cor)\n",
    "\n",
    "# Visualize the image and the extracted plate\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(False)\n",
    "plt.imshow(preprocess_image(test_image))\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(False)\n",
    "plt.imshow(LpImg[0])\n",
    "\n",
    "plt.savefig(\"Image and License Plate Detection_2.jpg\",dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(LpImg)): #check if there is an license image\n",
    "    # Scale, calculates absolute values, and convert to 8-bit\n",
    "    plate_image = cv2.convertScaleAbs(LpImg[0], alpha=(255.0))\n",
    "\n",
    "    # grayscale and blur the image\n",
    "    gray = cv2.cvtColor(plate_image, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray,(7,7),0)\n",
    "\n",
    "    # inversed binary thresholding and dilating\n",
    "    binary = cv2.threshold(blur, 180, 255,\n",
    "                         cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    kernel3 = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    thre_mor = cv2.morphologyEx(binary, cv2.MORPH_DILATE, kernel3)\n",
    "\n",
    "\n",
    "# visualize preprocessed license plate\n",
    "fig = plt.figure(figsize=(12,7))\n",
    "plt.rcParams.update({\"font.size\":18})\n",
    "grid = gridspec.GridSpec(ncols=2,nrows=3,figure = fig)\n",
    "plot_image = [plate_image, gray, blur, binary,thre_mor]\n",
    "plot_name = [\"plate_image\",\"gray\",\"blur\",\"binary\",\"dilation\"]\n",
    "\n",
    "for i in range(len(plot_image)):\n",
    "    fig.add_subplot(grid[i])\n",
    "    plt.axis(False)\n",
    "    plt.title(plot_name[i])\n",
    "    if i ==0:\n",
    "        plt.imshow(plot_image[i])\n",
    "    else:\n",
    "        plt.imshow(plot_image[i],cmap=\"gray\")\n",
    "\n",
    "plt.savefig(\"License plate preprocessing_2.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_contours(cnts,reverse = False):\n",
    "    i = 0\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "                                        key=lambda b: b[1][i], reverse=reverse))\n",
    "    return cnts\n",
    "\n",
    "cont, _  = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "test_roi = plate_image.copy()\n",
    "\n",
    "# a list to append segmented character images\n",
    "crop_characters = []\n",
    "\n",
    "# standard filter for width and height of character\n",
    "digit_w, digit_h = 30, 60\n",
    "\n",
    "for c in sort_contours(cont):\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    ratio = h/w\n",
    "    if 1<=ratio<=3.5: # Only select contour with defined ratio\n",
    "        if h/plate_image.shape[0]>=0.5: # Select contours height larger than 50% of the plate\n",
    "            # Draw bounding box around character\n",
    "            cv2.rectangle(test_roi, (x, y), (x + w, y + h), (0, 255,0), 2)\n",
    "\n",
    "            # Seperate characters and append to list\n",
    "            curr_num = thre_mor[y:y+h,x:x+w]\n",
    "            curr_num = cv2.resize(curr_num, dsize=(digit_w, digit_h))\n",
    "            # convert characters to binary\n",
    "            _, curr_num = cv2.threshold(curr_num, 220, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            crop_characters.append(curr_num)\n",
    "\n",
    "print(\"Detected {} characters.\".format(len(crop_characters)))\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "plt.axis(False)\n",
    "plt.imshow(test_roi)\n",
    "plt.savefig('Bounded and Segmented Characters_2.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the segmented characters in the list one by one, in a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,4))\n",
    "grid = gridspec.GridSpec(ncols=len(crop_characters),nrows=1,figure=fig)\n",
    "\n",
    "for i in range(len(crop_characters)):\n",
    "    fig.add_subplot(grid[i])\n",
    "    plt.axis(False)\n",
    "    plt.imshow(crop_characters[i],cmap=\"gray\")\n",
    "plt.savefig(\"Segmented Characters_2.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Dataset For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset_paths = glob.glob(\"dataset_characters/CNN_letter_Dataset/**/*.jpg\")\n",
    "\n",
    "cols = 4\n",
    "rows = 3\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "plt.rcParams.update({\"font.size\": 14})\n",
    "grid = gridspec.GridSpec(ncols=cols, nrows=rows, figure=fig)\n",
    "\n",
    "# Calculate the number of images in the dataset\n",
    "num_images = len(dataset_paths)\n",
    "\n",
    "# Check if there are enough images to fill the grid\n",
    "if num_images >= (cols * rows):\n",
    "    # Generate random indices\n",
    "    np.random.seed(45)\n",
    "    rand = np.random.choice(num_images, size=(cols * rows), replace=False)\n",
    "\n",
    "    # Plot characters and their labels\n",
    "    for i in range(cols * rows):\n",
    "        fig.add_subplot(grid[i])\n",
    "        image = load_img(dataset_paths[rand[i]])\n",
    "        label = dataset_paths[rand[i]].split(os.path.sep)[-2]\n",
    "        plt.title('\"{:s}\"'.format(label))\n",
    "        plt.axis(False)\n",
    "        plt.imshow(image)\n",
    "\n",
    "    plt.savefig(\"Sample of Dataset Characters.png\", dpi=300)\n",
    "else:\n",
    "    print(\"Not enough images in the dataset to fill the grid.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing for Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]# character data in array form\n",
    "labels=[]# labels\n",
    "\n",
    "for image_path in dataset_paths:\n",
    "    label = image_path.split(os.path.sep)[-2]\n",
    "    image=load_img(image_path,target_size=(80,80))\n",
    "    image=img_to_array(image)\n",
    "\n",
    "    X.append(image)\n",
    "    labels.append(label)\n",
    "\n",
    "X = np.array(X,dtype=\"float16\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"Found {:d} images with {:d} classes\".format(len(X),len(set(labels))))\n",
    "\n",
    "\n",
    "# encode the labels for equal representation\n",
    "lb = LabelEncoder()\n",
    "lb.fit(labels)\n",
    "labels = lb.transform(labels)\n",
    "y = to_categorical(labels)\n",
    "\n",
    "# save label file for reuse\n",
    "np.save('license_character_classes.npy', lb.classes_)\n",
    "\n",
    "# split 10% of data as validation set\n",
    "(trainX, testX, trainY, testY) = train_test_split(X, y, test_size=0.10, stratify=y, random_state=42)\n",
    "\n",
    "# data augumentation to diversify the training set\n",
    "image_gen = ImageDataGenerator(rotation_range=10,\n",
    "                              width_shift_range=0.1,\n",
    "                              height_shift_range=0.1,\n",
    "                              shear_range=0.1,\n",
    "                              zoom_range=0.1,\n",
    "                              fill_mode=\"nearest\"\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate=1e-4, decay=1e-4/25, training=False, output_shape=y.shape[1]):\n",
    "    baseModel = MobileNetV2(weights=\"imagenet\",\n",
    "                            include_top=False,\n",
    "                            input_tensor=Input(shape=(80, 80, 3)))\n",
    "\n",
    "    headModel = baseModel.output\n",
    "    headModel = AveragePooling2D(pool_size=(3, 3))(headModel)\n",
    "    headModel = Flatten(name=\"flatten\")(headModel)\n",
    "    headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "    headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "    headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.5)(headModel)\n",
    "    headModel = Dense(output_shape, activation=\"softmax\")(headModel)\n",
    "\n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "    if training:\n",
    "        # Define trainable layers in the base model\n",
    "        for layer in baseModel.layers:\n",
    "            layer.trainable = True\n",
    "\n",
    "        # Compile the model with learning rate and loss function\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Initialize hyperparameters\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(learning_rate=INIT_LR, decay=INIT_LR/EPOCHS, training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 300\n",
    "\n",
    "my_checkpointer = [\n",
    "                EarlyStopping(monitor='val_loss', patience=5, verbose=0),\n",
    "                ModelCheckpoint(filepath=\"License_character_recognition_weight (1).h5\", verbose=1, save_weights_only=True)\n",
    "                ]\n",
    "\n",
    "result = model.fit(image_gen.flow(trainX, trainY, batch_size=BATCH_SIZE),\n",
    "                   steps_per_epoch=len(trainX) // BATCH_SIZE,\n",
    "                   validation_data=(testX, testY),\n",
    "                   validation_steps=len(testX) // BATCH_SIZE,\n",
    "                   epochs=EPOCHS, callbacks=my_checkpointer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,5))\n",
    "grid=gridspec.GridSpec(ncols=2,nrows=1,figure=fig)\n",
    "fig.add_subplot(grid[0])\n",
    "plt.plot(result.history['accuracy'], label='training accuracy')\n",
    "plt.plot(result.history['val_accuracy'], label='val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(grid[1])\n",
    "plt.plot(result.history['loss'], label='training loss')\n",
    "plt.plot(result.history['val_loss'], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"Training and Validation Curves.jpg\",dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"MobileNets_character_recognition_model.json\", \"w\") as json_file:\n",
    "  json_file.write(model_json)\n",
    "json_file = open('MobileNets_character_recognition_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights(\"License_character_recognition_weight (1).h5\")\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "labels = LabelEncoder()\n",
    "labels.classes_ = np.load('license_character_classes.npy')\n",
    "print(\"Labels loaded successfully!\")\n",
    "\n",
    "def predict_from_model(image,model,labels):\n",
    "    image = cv2.resize(image,(80,80))\n",
    "    image = np.stack((image,)*3, axis=-1)\n",
    "    prediction = labels.inverse_transform([np.argmax(model.predict(image[np.newaxis,:]))])\n",
    "    return prediction\n",
    "# display the each of segmented characters in a grid and the predicted labels as the title.\n",
    "fig = plt.figure(figsize=(15,3))\n",
    "cols = len(crop_characters)\n",
    "grid = gridspec.GridSpec(ncols=cols,nrows=1,figure=fig)\n",
    "\n",
    "final_string = ''\n",
    "for i,character in enumerate(crop_characters):\n",
    "    fig.add_subplot(grid[i])\n",
    "    title = np.array2string(predict_from_model(character,model,labels))\n",
    "    plt.title('{}'.format(title.strip(\"'[]\"),fontsize=10))\n",
    "    final_string+=title.strip(\"'[]\")\n",
    "    plt.axis(False)\n",
    "    plt.imshow(character,cmap='gray')\n",
    "\n",
    "print(final_string)\n",
    "plt.savefig('Recognized License Plate_2.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
